# Przewidywanie ToksycznoÅ›ci Komentarzy - Kurs Machine Learning

## ğŸ“ Opis projektu

Ten projekt pokazuje, jak stworzyÄ‡ system automatycznego wykrywania toksycznoÅ›ci w komentarzach internetowych uÅ¼ywajÄ…c technik uczenia maszynowego. Program analizuje teksty i przewiduje poziom toksycznoÅ›ci w rÃ³Å¼nych kategoriach.

âš¡ **NOWOÅšÄ†:** Program automatycznie zapisuje wytrenowany model! Pierwsze uruchomienie zajmuje kilka minut, ale nastÄ™pne sÄ… natychmiastowe.

## ğŸ¯ Co siÄ™ nauczysz

- Jak Å‚adowaÄ‡ i przetwarzaÄ‡ zbiory danych tekstowych
- Jak przeksztaÅ‚caÄ‡ tekst na liczby (TF-IDF)
- Jak trenowaÄ‡ model uczenia maszynowego
- Jak oceniaÄ‡ jakoÅ›Ä‡ modelu
- Jak uÅ¼ywaÄ‡ modelu do przewidywaÅ„
- **Jak zapisywaÄ‡ i Å‚adowaÄ‡ wytrenowane modele (optymalizacja)**

## ğŸ“š Wymagania

```bash
pip install datasets pandas scikit-learn
```

### Biblioteki uÅ¼ywane w projekcie:

- **datasets** - Å‚adowanie gotowych zbiorÃ³w danych
- **pandas** - manipulacja danymi
- **scikit-learn** - narzÄ™dzia do uczenia maszynowego
- **joblib** - zapisywanie i Å‚adowanie modelÃ³w (wbudowana w scikit-learn)
- **os.path** - sprawdzanie istnienia plikÃ³w (wbudowana w Python)

## ğŸ’¾ Automatyczne zapisywanie modelu

### âš¡ SzybkoÅ›Ä‡ uruchomieÅ„

**Pierwsze uruchomienie (~5-10 minut):**
1. ğŸ”„ Åadowanie danych z internetu
2. ğŸ§  Trenowanie modelu regresji liniowej
3. ğŸ“Š Testowanie jakoÅ›ci modelu
4. ğŸ’¾ Automatyczne zapisanie modelu na dysk

**Kolejne uruchomienia (~2-5 sekund):**
1. âœ… Znalezienie zapisanych plikÃ³w
2. âš¡ BÅ‚yskawiczne wczytanie modelu
3. ğŸš€ Natychmiastowe uruchomienie testÃ³w

### ğŸ“ Pliki modelu

Program automatycznie tworzy dwa pliki:

- **`model.joblib`** - wytrenowany model regresji liniowej
- **`vectorizer.joblib`** - wytrenowany vectorizer TF-IDF

**âš ï¸ WaÅ¼ne:** Oba pliki sÄ… potrzebne do dziaÅ‚ania programu. Nie usuwaj ich!

### ğŸ”„ Re-trenowanie modelu

JeÅ›li chcesz wytrenowaÄ‡ model od nowa:
1. UsuÅ„ pliki `model.joblib` i `vectorizer.joblib`
2. Uruchom program ponownie - automatycznie wytrenuje nowy model

### ğŸ› ï¸ Troubleshooting

**Problem:** Program siÄ™ zawiesza lub pokazuje bÅ‚Ä™dy
- **RozwiÄ…zanie:** UsuÅ„ pliki `.joblib` i uruchom ponownie

**Problem:** Wyniki sÄ… dziwne po aktualizacji kodu
- **RozwiÄ…zanie:** UsuÅ„ stare pliki modelu, aby wytrenowaÄ‡ nowy

**Problem:** Brak miejsca na dysku
- **RozwiÄ…zanie:** Pliki modelu zajmujÄ… ~50MB - sprawdÅº miejsce na dysku

## ğŸ”¬ Krok po kroku - jak dziaÅ‚a kod

Program ma teraz **inteligentnÄ… logikÄ™** - sprawdza czy model juÅ¼ istnieje!

### 1. ğŸ” Sprawdzenie czy model istnieje

```python
if models_exist():
    model, vectorizer = load_model_and_vectorizer()
else:
    model, vectorizer = train_new_model()
```

**Co siÄ™ dzieje:**
- Program sprawdza czy istniejÄ… pliki `model.joblib` i `vectorizer.joblib`
- **JeÅ›li TAK:** Åaduje zapisane modele (szybko! âš¡)
- **JeÅ›li NIE:** Trenuje nowe modele (wolno, ale tylko raz ğŸŒâ†’âš¡)

---

## ğŸš€ ÅšcieÅ¼ka A: Model juÅ¼ istnieje (kolejne uruchomienia)

### BÅ‚yskawiczne Å‚adowanie

```python
model = joblib.load("model.joblib")
vectorizer = joblib.load("vectorizer.joblib")
```

**Co siÄ™ dzieje:**
- Wczytanie zapisanego modelu z dysku (~1 sekunda)
- Wczytanie zapisanego vectorizera (~1 sekunda) 
- PrzejÅ›cie bezpoÅ›rednio do testÃ³w

---

## ğŸŒ ÅšcieÅ¼ka B: Pierwszy raz (trenowanie nowego modelu)

### 2. Åadowanie danych

```python
dataset = load_dataset("google/civil_comments")
df = dataset["train"].to_pandas()
```

**Co siÄ™ dzieje:**
- Pobieramy zbiÃ³r danych "Civil Comments" od Google
- Zawiera prawdziwe komentarze z internetu z ocenami ekspertÃ³w
- Konwertujemy na format pandas DataFrame dla Å‚atwiejszej pracy

### 3. Przygotowanie etykiet

```python
labels = ["toxicity", "severe_toxicity", "obscene", "threat", "insult", "identity_attack", "sexual_explicit"]
X = df["text"]  # Teksty komentarzy (dane wejÅ›ciowe)
y = df[labels]  # Oceny toksycznoÅ›ci (dane wyjÅ›ciowe)
```

**Rodzaje toksycznoÅ›ci:**
- `toxicity` - ogÃ³lna toksycznoÅ›Ä‡
- `severe_toxicity` - powaÅ¼na toksycznoÅ›Ä‡  
- `obscene` - wulgarnoÅ›Ä‡
- `threat` - groÅºby
- `insult` - obelgi
- `identity_attack` - ataki na toÅ¼samoÅ›Ä‡
- `sexual_explicit` - treÅ›ci seksualne

### 4. PodziaÅ‚ danych

```python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

**Dlaczego dzielimy dane:**
- **80% na trening** - do uczenia modelu
- **20% na test** - do sprawdzenia, czy model dziaÅ‚a na nowych danych
- `random_state=42` - zapewnia powtarzalne wyniki

### 5. PrzeksztaÅ‚canie tekstu na liczby (TF-IDF)

```python
vectorizer = TfidfVectorizer(max_features=5000)
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)
```

**Co to jest TF-IDF:**
- **TF (Term Frequency)** - jak czÄ™sto sÅ‚owo pojawia siÄ™ w dokumencie
- **IDF (Inverse Document Frequency)** - jak rzadkie jest sÅ‚owo w caÅ‚ym zbiorze
- **Efekt:** WaÅ¼ne sÅ‚owa majÄ… wyÅ¼szÄ… wartoÅ›Ä‡, popularne sÅ‚owa (jak "i", "a") majÄ… niÅ¼szÄ…

**PrzykÅ‚ad:**
- Komentarz: "Ten film jest okropny"
- TF-IDF zamienia to na wektor liczb: [0.0, 0.3, 0.0, 0.8, 0.5, ...]
- KaÅ¼da pozycja odpowiada jednemu sÅ‚owu ze sÅ‚ownika

### 6. Trenowanie modelu

```python
model = LinearRegression()
model.fit(X_train_tfidf, y_train)
```

**Regresja liniowa:**
- Znajduje liniowÄ… zaleÅ¼noÅ›Ä‡ miÄ™dzy sÅ‚owami a poziomem toksycznoÅ›ci
- Dla kaÅ¼dego sÅ‚owa przypisuje wagÄ™ (dodatniÄ… lub ujemnÄ…)
- SÅ‚owa jak "stupid", "hate" dostanÄ… wysokie wagi dodatnie
- SÅ‚owa jak "love", "thank you" dostanÄ… wagi ujemne

### 7. Ocena i zapis modelu

```python
y_pred = model.predict(X_test_tfidf)
print(f"Mean squared error: {mean_squared_error(y_test, y_pred)}")
print(f"R2 score: {r2_score(y_test, y_pred)}")

# Automatyczny zapis modelu na przyszÅ‚oÅ›Ä‡!
joblib.dump(model, "model.joblib")
joblib.dump(vectorizer, "vectorizer.joblib")
```

**Metryki:**
- **MSE (Mean Squared Error)** - Å›redni bÅ‚Ä…d kwadratowy
  - Im mniejszy, tym lepiej
  - Pokazuje, jak bardzo nasze przewidywania odbiegajÄ… od rzeczywistoÅ›ci
- **RÂ² Score** - wspÃ³Å‚czynnik determinacji  
  - WartoÅ›ci od 0 do 1 (moÅ¼e byÄ‡ ujemny dla bardzo zÅ‚ych modeli)
  - Im bliÅ¼ej 1, tym lepiej model wyjaÅ›nia dane

**ğŸ’¾ Zapis:** Model i vectorizer sÄ… automatycznie zapisywane na dysk!

---

## ğŸ¯ WspÃ³lna czÄ™Å›Ä‡: Testowanie modelu

NiezaleÅ¼nie od Å›cieÅ¼ki (A lub B), na koÅ„cu program uÅ¼ywa gotowego modelu do testÃ³w:

## ğŸš€ Jak uruchomiÄ‡ program

```bash
python main.py
```

### ğŸ¥‡ Pierwsze uruchomienie (moÅ¼e trwaÄ‡ 5-10 minut)

**Co zobaczyÄ‡:**
1. âš ï¸ "Nie znaleziono zapisanych plikÃ³w modelu"
2. ğŸ”„ "Rozpoczynanie treningu nowego modelu..."
3. ğŸ“Š PostÄ™p Å‚adowania danych i treningu
4. ğŸ“ˆ Metryki jakoÅ›ci modelu (MSE, RÂ²)
5. ğŸ’¾ "Model zapisany w: model.joblib"
6. ğŸ¯ Testy na przykÅ‚adowych komentarzach

### âš¡ Kolejne uruchomienia (2-5 sekund)

**Co zobaczyÄ‡:**
1. âœ… "Znaleziono zapisane pliki modelu!"
2. ğŸ“¦ "Model i vectorizer zaÅ‚adowane pomyÅ›lnie!"
3. âš¡ "PominiÄ™to trening - uÅ¼ywamy gotowego modelu!"
4. ğŸ¯ Natychmiastowe testy na przykÅ‚adowych komentarzach

**ğŸ’¡ WskazÃ³wka:** UsuÅ„ pliki `.joblib` jeÅ›li chcesz ponownie wytrenowaÄ‡ model.

## ğŸ’¡ PrzykÅ‚ady uÅ¼ycia

Program automatycznie testuje 3 komentarze:

### Test 1: "This is a terrible comment."
- **Oczekiwany wynik:** Å›rednia toksycznoÅ›Ä‡
- **Dlaczego:** sÅ‚owo "terrible" ma negatywnÄ… konotacjÄ™

### Test 2: "This is a very nice comment. Thank you!"
- **Oczekiwany wynik:** niska toksycznoÅ›Ä‡  
- **Dlaczego:** pozytywne sÅ‚owa jak "nice", "thank you"

### Test 3: "I want to harm you!"
- **Oczekiwany wynik:** wysoka toksycznoÅ›Ä‡
- **Dlaczego:** jawna groÅºba

## ğŸ“Š Interpretacja wynikÃ³w

KaÅ¼dy komentarz otrzymuje 7 ocen (po jednej dla kaÅ¼dej etykiety):

```python
# PrzykÅ‚adowy wynik:
[0.1, 0.05, 0.02, 0.8, 0.1, 0.03, 0.01]
#  |     |     |    |    |     |     |
#  |     |     |    |    |     |     â””â”€ sexual_explicit: 0.01 (bardzo niska)
#  |     |     |    |    |     â””â”€ identity_attack: 0.03 (niska) 
#  |     |     |    |    â””â”€ insult: 0.1 (niska)
#  |     |     |    â””â”€ threat: 0.8 (wysoka!) 
#  |     |     â””â”€ obscene: 0.02 (bardzo niska)
#  |     â””â”€ severe_toxicity: 0.05 (niska)
#  â””â”€ toxicity: 0.1 (niska)
```

**Interpretacja:**
- WartoÅ›ci bliskie 0: niska toksycznoÅ›Ä‡
- WartoÅ›ci bliskie 1: wysoka toksycznoÅ›Ä‡  
- W przykÅ‚adzie: komentarz ma wysokÄ… ocenÄ™ za "threat" (groÅºbÄ™)

## ğŸ”§ Jak testowaÄ‡ wÅ‚asne komentarze

Dodaj na koÅ„cu pliku `main.py`:

```python
# Testuj wÅ‚asne komentarze
moj_komentarz = "Wpisz tutaj swÃ³j komentarz"
wynik = get_comment_rating(moj_komentarz)
print(f"Wyniki dla '{moj_komentarz}':")
for i, etykieta in enumerate(labels):
    print(f"{etykieta}: {wynik[i]:.3f}")
```

## ğŸ“ˆ Jak ulepszyÄ‡ model

### 1. Lepsze przetwarzanie tekstu
```python
# Dodaj wiÄ™cej funkcji TF-IDF
vectorizer = TfidfVectorizer(
    max_features=10000,  # wiÄ™cej sÅ‚Ã³w
    ngram_range=(1, 2),  # uÅ¼ywaj par sÅ‚Ã³w
    min_df=2,           # ignoruj bardzo rzadkie sÅ‚owa
    stop_words='english' # usuÅ„ stop words
)
```

### 2. Inne modele
```python
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR

# Random Forest - zwykle lepszy niÅ¼ regresja liniowa
model = RandomForestRegressor(n_estimators=100)

# Support Vector Machine
model = SVR(kernel='rbf')
```

### 3. Walidacja krzyÅ¼owa
```python
from sklearn.model_selection import cross_val_score

# SprawdÅº model na rÃ³Å¼nych podziaÅ‚ach danych
scores = cross_val_score(model, X_train_tfidf, y_train, cv=5)
print(f"Åšredni wynik: {scores.mean():.3f}")
```

## ğŸ“ Koncepty ML wyjaÅ›nione

### Co to jest supervised learning?
- Mamy dane wejÅ›ciowe (komentarze) i oczekiwane wyniki (oceny toksycznoÅ›ci)
- Model uczy siÄ™ na przykÅ‚adach z prawidÅ‚owymi odpowiedziami
- Potem moÅ¼e przewidywaÄ‡ dla nowych danych

### Dlaczego dzielimy dane na train/test?
- **Overfitting** - model moÅ¼e "zapamiÄ™taÄ‡" dane treningowe
- Test na oddzielnych danych pokazuje rzeczywistÄ… jakoÅ›Ä‡
- Jak egzamin - nie moÅ¼na siÄ™ uczyÄ‡ z pytaÅ„ egzaminacyjnych

### Czym rÃ³Å¼ni siÄ™ regresja od klasyfikacji?
- **Klasyfikacja:** przewiduje kategorie (spam/nie spam)
- **Regresja:** przewiduje liczby (poziom toksycznoÅ›ci od 0 do 1)
- UÅ¼ywamy regresji, bo toksycznoÅ›Ä‡ to wartoÅ›Ä‡ ciÄ…gÅ‚a

## âš ï¸ Ograniczenia

1. **JÄ™zyk:** Model trenowany na jÄ™zyku angielskim
2. **Kontekst:** MoÅ¼e nie rozumieÄ‡ sarkazmu czy ironii  
3. **StronniczoÅ›Ä‡:** MoÅ¼e mieÄ‡ uprzedzenia ze zbioru treningowego
4. **Prosty model:** Regresja liniowa ma ograniczenia

## ğŸ”„ NastÄ™pne kroki

1. **SprÃ³buj innych modeli:** Random Forest, Neural Networks
2. **Lepsze preprocessing:** stemming, lemmatizacja
3. **WiÄ™cej danych:** uÅ¼yj wiÄ™kszego zbioru
4. **GÅ‚Ä™bokie uczenie:** BERT, transformers
5. **Ewaluacja:** wiÄ™cej metryk, confusion matrix

## ğŸ“– Dodatkowe materiaÅ‚y

- [Scikit-learn documentation](https://scikit-learn.org/)
- [TF-IDF wyjaÅ›nienie](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)
- [Civil Comments Dataset](https://www.tensorflow.org/datasets/catalog/civil_comments)

---

**Gratulacje!** ğŸ‰ WÅ‚aÅ›nie stworzyÅ‚eÅ› swÃ³j pierwszy model do analizy sentymentu. To podstawy, ktÃ³re moÅ¼esz rozwijaÄ‡ w bardziej zaawansowanych projektach ML.