# PRZEWIDYWANIE TOKSYCZNOÅšCI KOMENTARZY
# Program wykorzystuje uczenie maszynowe do przewidywania poziomu toksycznoÅ›ci w komentarzach
# Z AUTOMATYCZNYM ZAPISYWANIEM I ÅADOWANIEM MODELU!

# Importowanie bibliotek potrzebnych do pracy z danymi i uczeniem maszynowym
from datasets import load_dataset  # Biblioteka do Å‚adowania gotowych zbiorÃ³w danych
import pandas as pd  # Biblioteka do manipulacji danymi (DataFrame, analiza danych)
from sklearn.model_selection import train_test_split  # Funkcja do podziaÅ‚u danych na zbiÃ³r treningowy i testowy
from sklearn.feature_extraction.text import TfidfVectorizer  # PrzeksztaÅ‚ca tekst na liczby (wektory TF-IDF)
from sklearn.linear_model import LinearRegression  # Model regresji liniowej do przewidywania
from sklearn.metrics import mean_squared_error, r2_score  # Metryki do oceny jakoÅ›ci modelu
import joblib  # Najlepsza biblioteka do zapisywania modelÃ³w scikit-learn (szybsza niÅ¼ pickle)
import os.path  # Do sprawdzania czy pliki istniejÄ…

# Definiujemy Å›cieÅ¼ki do plikÃ³w, w ktÃ³rych bÄ™dziemy zapisywaÄ‡ wytrenowany model i vectorizer
MODEL_FILE = "model.joblib"  # Plik z wytrenowanym modelem regresji liniowej
VECTORIZER_FILE = "vectorizer.joblib"  # Plik z wytrenowanym vectorizerem TF-IDF

# Definiujemy etykiety (labels) - rÃ³Å¼ne rodzaje toksycznoÅ›ci, ktÃ³re chcemy przewidywaÄ‡
labels = ["toxicity", "severe_toxicity", "obscene", "threat", "insult", "identity_attack", "sexual_explicit"]


# FUNKCJE DO ZARZÄ„DZANIA MODELEM

def models_exist():
    """Sprawdza czy zapisane pliki modelu i vectorizera istniejÄ… na dysku"""
    # os.path.exists() zwraca True jeÅ›li plik istnieje, False jeÅ›li nie
    model_exists = os.path.exists(MODEL_FILE)
    vectorizer_exists = os.path.exists(VECTORIZER_FILE)
    # Oba pliki muszÄ… istnieÄ‡, Å¼eby mÃ³c zaÅ‚adowaÄ‡ kompletny model
    return model_exists and vectorizer_exists


def save_model_and_vectorizer(model, vectorizer):
    """Zapisuje wytrenowany model i vectorizer do plikÃ³w .joblib"""
    print("\nğŸ’¾ Zapisywanie modelu i vectorizera na dysk...")
    # joblib.dump() zapisuje obiekty do pliku - szybsze i bardziej efektywne niÅ¼ pickle dla numpy
    joblib.dump(model, MODEL_FILE)  # Zapisujemy model regresji liniowej
    joblib.dump(vectorizer, VECTORIZER_FILE)  # Zapisujemy vectorizer TF-IDF
    print(f"âœ… Model zapisany w: {MODEL_FILE}")
    print(f"âœ… Vectorizer zapisany w: {VECTORIZER_FILE}")
    print("\nKolejne uruchomienia bÄ™dÄ… znacznie szybsze! âš¡")


def load_model_and_vectorizer():
    """Wczytuje zapisany model i vectorizer z plikÃ³w .joblib"""
    print("\nğŸ“¦ Åadowanie zapisanego modelu z dysku...")
    # joblib.load() wczytuje obiekty z pliku
    model = joblib.load(MODEL_FILE)  # Wczytujemy zapisany model
    vectorizer = joblib.load(VECTORIZER_FILE)  # Wczytujemy zapisany vectorizer
    print("âœ… Model i vectorizer zaÅ‚adowane pomyÅ›lnie!")
    print("âš¡ PominiÄ™to trening - uÅ¼ywamy gotowego modelu!")
    return model, vectorizer


def train_new_model():
    """Trenuje nowy model od zera - wywoÅ‚ywane tylko gdy brak zapisanych plikÃ³w"""
    print("\nğŸƒ Rozpoczynanie treningu nowego modelu...")
    print("To moÅ¼e potrwaÄ‡ kilka minut - nastÄ™pne uruchomienia bÄ™dÄ… szybsze!")
    
    # Åadowanie zbioru danych "civil_comments" od Google - zawiera komentarze z ocenami toksycznoÅ›ci
    print("\n1ï¸âƒ£ Åadowanie danych z internetu...")
    dataset = load_dataset("google/civil_comments")
    # Konwertowanie zbioru treningowego na DataFrame pandas dla Å‚atwiejszej manipulacji
    df = dataset["train"].to_pandas()
    
    # WyÅ›wietlenie podstawowych informacji o zbiorze danych (ile wierszy, jakie kolumny)
    print(f"âœ… ZaÅ‚adowano {len(df)} komentarzy do analizy")
    
    # X to dane wejÅ›ciowe - teksty komentarzy (cechy/features)
    X = df["text"]
    # y to dane wyjÅ›ciowe - oceny toksycznoÅ›ci dla kaÅ¼dej kategorii (target/etykiety)
    y = df[labels]
    
    # PodziaÅ‚ danych na zbiÃ³r treningowy (80%) i testowy (20%)
    print("\n2ï¸âƒ£ PodziaÅ‚ danych na trening i test...")
    # X_train, y_train - dane do uczenia modelu
    # X_test, y_test - dane do testowania jakoÅ›ci modelu
    # random_state=42 zapewnia powtarzalne wyniki
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    print(f"âœ… Dane treningowe: {len(X_train)} komentarzy")
    print(f"âœ… Dane testowe: {len(X_test)} komentarzy")

    # PrzykÅ‚ad zastosowania TF-IDF dla jÄ™zyka polskiego - EDUKACYJNE WYJAÅšNIENIE
    # ZaÅ‚Ã³Å¼my, Å¼e mamy dwa zdania w jÄ™zyku polskim:
    # "Kot biega po ogrodzie." vs "Kotka biega po ogrodzie."
    # TF-IDF najpierw tokenizuje tekst: ["Kot", "biega", "po", "ogrodzie"] vs ["Kotka", "biega", "po", "ogrodzie"]
    # Problem: "Kot" i "Kotka" to rÃ³Å¼ne tokeny, ale to samo znaczenie
    # RozwiÄ…zanie: lematyzacja sprowadza do: ["Kot", "biegaÄ‡", "po", "ogrÃ³d"]
    
    print("\n3ï¸âƒ£ Tworzenie vectorizera TF-IDF...")
    # Tworzenie wektoryzera TF-IDF - przeksztaÅ‚ca tekst na liczby
    # max_features=5000 oznacza, Å¼e uÅ¼ywamy tylko 5000 najwaÅ¼niejszych sÅ‚Ã³w
    vectorizer = TfidfVectorizer(max_features=5000)
    # Uczenie wektoryzera na danych treningowych i przeksztaÅ‚canie tekstu na wektory liczb
    X_train_tfidf = vectorizer.fit_transform(X_train)
    # PrzeksztaÅ‚canie danych testowych uÅ¼ywajÄ…c juÅ¼ nauczonego wektoryzera
    X_test_tfidf = vectorizer.transform(X_test)
    print("âœ… Vectorizer TF-IDF wytrenowany!")
    
    print("\n4ï¸âƒ£ Trenowanie modelu regresji liniowej...")
    # Tworzenie modelu regresji liniowej - znajdzie liniowÄ… zaleÅ¼noÅ›Ä‡ miÄ™dzy sÅ‚owami a toksycznoÅ›ciÄ…
    model = LinearRegression()
    # Uczenie modelu na danych treningowych (wektory TF-IDF + etykiety toksycznoÅ›ci)
    model.fit(X_train_tfidf, y_train)
    print("âœ… Model regresji liniowej wytrenowany!")
    
    print("\n5ï¸âƒ£ Testowanie jakoÅ›ci modelu...")
    # Przewidywanie poziomÃ³w toksycznoÅ›ci dla danych testowych
    y_pred = model.predict(X_test_tfidf)
    # Mean Squared Error - Å›redni bÅ‚Ä…d kwadratowy (im mniejszy, tym lepiej)
    mse = mean_squared_error(y_test, y_pred)
    # R2 score - wspÃ³Å‚czynnik determinacji (im bliÅ¼ej 1, tym lepiej model wyjaÅ›nia dane)
    r2 = r2_score(y_test, y_pred)
    
    print(f"Mean squared error: {mse:.4f}")
    print(f"R2 score: {r2:.4f}")
    
    # Zapisz wytrenowany model i vectorizer do plikÃ³w
    save_model_and_vectorizer(model, vectorizer)
    
    return model, vectorizer


# GÅÃ“WNA LOGIKA PROGRAMU - SPRAWDZANIE CZY MODEL ISTNIEJE
print("="*60)
print("ğŸ¤– SYSTEM PRZEWIDYWANIA TOKSYCZNOÅšCI KOMENTARZY")
print("="*60)

# Sprawdzamy czy zapisane pliki modelu juÅ¼ istniejÄ… na dysku
if models_exist():
    print("\nğŸ” Znaleziono zapisane pliki modelu!")
    # JeÅ›li pliki istniejÄ…, po prostu je wczytujemy (szybko!)
    model, vectorizer = load_model_and_vectorizer()
else:
    print("\nâš ï¸ Nie znaleziono zapisanych plikÃ³w modelu.")
    print("Trenowanie nowego modelu...")
    # JeÅ›li plikÃ³w nie ma, trenujemy nowy model (dÅ‚ugo, ale tylko raz!)
    model, vectorizer = train_new_model()

print("\n" + "="*60)
print("ğŸ‰ MODEL GOTOWY DO UÅ»YCIA!")
print("="*60)


# FUNKCJA DO OCENY TOKSYCZNOÅšCI POJEDYNCZEGO KOMENTARZA
def get_comment_rating(comment):
    """Analizuje pojedynczy komentarz i zwraca przewidywane poziomy toksycznoÅ›ci"""
    # PrzeksztaÅ‚cenie nowego komentarza na wektor TF-IDF uÅ¼ywajÄ…c zaÅ‚adowanego/wytrenowanego vectorizera
    comment_tfidf = vectorizer.transform([comment])
    # Przewidywanie poziomÃ³w toksycznoÅ›ci za pomocÄ… zaÅ‚adowanego/wytrenowanego modelu
    # Zwracamy pierwszy (i jedyny) wynik - tablicÄ™ z 7 wartoÅ›ciami dla 7 etykiet
    return model.predict(comment_tfidf)[0]


# TESTOWANIE MODELU NA PRZYKÅADOWYCH KOMENTARZACH
print("\nğŸ“Š ROZPOCZYNANIE TESTÃ“W MODELU")
print("-" * 40)

# WyÅ›wietlenie listy etykiet, aby wiedzieÄ‡, co oznacza kaÅ¼dy wynik
print("\nğŸ·ï¸ Etykiety analizowane przez model:")
for i, label in enumerate(labels):
    print(f"{i}: {label}")
print("\n(Im wyÅ¼sza wartoÅ›Ä‡, tym wiÄ™ksza toksycznoÅ›Ä‡ w danej kategorii)")

# TEST 1: Komentarz potencjalnie toksyczny
print("\nğŸ”´ TEST 1: Komentarz negatywny")
new_comment = "This is a terrible comment."
result1 = get_comment_rating(new_comment)
print(f"Komentarz: '{new_comment}'")
print(f"Wszystkie wyniki: {result1}")
print(f"GÅ‚Ã³wna toksycznoÅ›Ä‡: {result1[0]:.3f}")

# TEST 2: Komentarz pozytywny (powinien mieÄ‡ niskÄ… toksycznoÅ›Ä‡)
print("\nğŸŸ¢ TEST 2: Komentarz pozytywny")
new_comment = "This is a very nice comment. Thank you!"
result2 = get_comment_rating(new_comment)
print(f"Komentarz: '{new_comment}'")
print(f"Wszystkie wyniki: {result2}")
print(f"GÅ‚Ã³wna toksycznoÅ›Ä‡: {result2[0]:.3f}")

# TEST 3: Komentarz wyraÅºnie toksyczny z groÅºbÄ… (powinien mieÄ‡ wysokÄ… toksycznoÅ›Ä‡)
print("\nğŸ”´ TEST 3: Komentarz z groÅºbÄ…")
new_comment = "I want to harm you!"
result3 = get_comment_rating(new_comment)
print(f"Komentarz: '{new_comment}'")
print(f"Wszystkie wyniki: {result3}")
print(f"GÅ‚Ã³wna toksycznoÅ›Ä‡: {result3[0]:.3f}")

print("\n" + "="*60)
print("ğŸ† TESTY ZAKOÅƒCZONE POMYÅšLNIE!")
print("NastÄ™pne uruchomienie bÄ™dzie niemal natychmiastowe dziÄ™ki zapisanemu modelowi.")
print("="*60)
