# System Wykrywania ToksycznoÅ›ci - Kurs Machine Learning

## ğŸ“ Opis projektu

Ten projekt pokazuje, jak stworzyÄ‡ automatyczny system wykrywania toksycznoÅ›ci w komentarzach internetowych przy uÅ¼yciu technik uczenia maszynowego. Program analizuje teksty i przewiduje poziomy toksycznoÅ›ci w rÃ³Å¼nych kategoriach.

**âœ¨ FUNKCJE:** Modularna architektura z oddzielnymi komponentami trenowania, testowania i analizy dla profesjonalnego przepÅ‚ywu pracy rozwoju!

## ğŸ¯ Czego siÄ™ nauczysz

- Jak Å‚adowaÄ‡ i przetwarzaÄ‡ zbiory danych tekstowych
- Jak konwertowaÄ‡ tekst na liczby (TF-IDF)
- Jak trenowaÄ‡ modele uczenia maszynowego
- Jak oceniaÄ‡ jakoÅ›Ä‡ modelu
- Jak uÅ¼ywaÄ‡ modeli do przewidywaÅ„
- **Jak zapisywaÄ‡ i Å‚adowaÄ‡ wytrenowane modele (optymalizacja)**
- **Profesjonalna struktura projektÃ³w Python**
- **Zasady programowania modularnego**

## ğŸ—ï¸ Struktura projektu

```
PODSTAWY/
â”œâ”€â”€ main.py                 # Interaktywny analizator komentarzy
â”œâ”€â”€ train_model.py         # Samodzielne trenowanie modelu
â”œâ”€â”€ test_model.py          # Testowanie i ocena
â”œâ”€â”€ config.py              # Konfiguracja i staÅ‚e
â”œâ”€â”€ model_utils.py         # NarzÄ™dzia zapisywania/Å‚adowania modelu
â”œâ”€â”€ text_processing.py     # Funkcje przetwarzania tekstu
â”œâ”€â”€ README.md              # Dokumentacja angielska
â”œâ”€â”€ README_PL.md           # Dokumentacja polska (ten plik)
â”œâ”€â”€ requirements.txt       # ZaleÅ¼noÅ›ci projektu
â”œâ”€â”€ pyproject.toml         # Nowoczesna konfiguracja projektu Python
â”œâ”€â”€ uv.lock                # Plik blokady zaleÅ¼noÅ›ci
â””â”€â”€ models/                # Zapisane pliki modelu
    â”œâ”€â”€ model.joblib
    â””â”€â”€ vectorizer.joblib
```

## ğŸ“š Wymagania

```bash
pip install -r requirements.txt
```

### Biblioteki uÅ¼ywane w projekcie:

- **datasets** - Å‚adowanie gotowych zbiorÃ³w danych
- **pandas** - manipulacja danymi
- **scikit-learn** - narzÄ™dzia uczenia maszynowego
- **joblib** - zapisywanie i Å‚adowanie modeli (wbudowana w scikit-learn)
- **numpy** - obliczenia numeryczne
- **scipy** - obliczenia naukowe

## ğŸš€ Przewodnik szybkiego startu

### Krok 1: Zainstaluj zaleÅ¼noÅ›ci
```bash
pip install -r requirements.txt
```

### Krok 2: Wytrenuj model (tylko pierwszy raz)
```bash
python train_model.py
```
*To zajmuje 5-10 minut, ale trzeba to zrobiÄ‡ tylko raz*

### Krok 3: Rozpocznij interaktywnÄ… analizÄ™
```bash
python main.py
```
*Natychmiastowe uruchomienie - analizuj komentarze w czasie rzeczywistym!*

### Krok 4: Uruchom testy (opcjonalnie)
```bash
python test_model.py
```

## ğŸ’¾ Automatyczne zapisywanie modelu

### âš¡ SzybkoÅ›Ä‡ uruchomienia

**Pierwsze trenowanie (`python train_model.py`) ~5-10 minut:**
1. ğŸ”„ Åadowanie danych z internetu
2. ğŸ§  Trenowanie modelu regresji liniowej
3. ğŸ“Š Testowanie jakoÅ›ci modelu
4. ğŸ’¾ Automatyczne zapisanie modelu na dysk

**Kolejne analizy (`python main.py`) ~2-5 sekund:**
1. âœ… Odnajdywanie zapisanych plikÃ³w
2. âš¡ BÅ‚yskawiczne Å‚adowanie modelu
3. ğŸš€ Natychmiastowa gotowoÅ›Ä‡ do analizy

### ğŸ“ Pliki modelu

System automatycznie tworzy dwa pliki w katalogu `models/`:

- **`model.joblib`** - wytrenowany model regresji liniowej
- **`vectorizer.joblib`** - wytrenowany wektorizer TF-IDF

**âš ï¸ WaÅ¼ne:** Oba pliki sÄ… potrzebne do dziaÅ‚ania systemu. Nie usuwaj ich!

### ğŸ”„ Ponowne trenowanie modelu

Aby wytrenowaÄ‡ nowy model od poczÄ…tku:
1. UsuÅ„ pliki `model.joblib` i `vectorizer.joblib` z katalogu `models/`
2. Uruchom `python train_model.py` - automatycznie wytrenuje nowy model

## ğŸ”¬ Jak to dziaÅ‚a - krok po kroku

System uÅ¼ywa **inteligentnej architektury** - kaÅ¼dy komponent ma okreÅ›lony cel!

### 1. ğŸ§  Pipeline trenowania (`train_model.py`)

```python
# Kompletny przepÅ‚yw pracy trenowania
def train_toxicity_model():
    X, y = load_training_data()                    # Åadowanie zbioru civil_comments
    X_train, X_test, y_train, y_test = split_data(X, y)  # 80% trening, 20% test
    vectorizer = create_vectorizer()               # Tworzenie procesora TF-IDF
    X_train_tfidf = vectorizer.fit_transform(X_train)    # Konwersja tekstu na liczby
    model = LinearRegression()                     # Tworzenie modelu
    model.fit(X_train_tfidf, y_train)            # Trenowanie modelu
    evaluate_model(model, X_test_tfidf, y_test)   # Test wydajnoÅ›ci
    save_model_and_vectorizer(model, vectorizer)  # Zapis do pÃ³Åºniejszego uÅ¼ycia
```

**Co siÄ™ dzieje:**
- Pobiera zbiÃ³r danych Civil Comments od Google (prawdziwe komentarze internetowe z ocenami ekspertÃ³w)
- Konwertuje do pandas DataFrame dla Å‚atwiejszej manipulacji
- Dzieli na zbiory treningowe (80%) i testowe (20%)
- Tworzy wektory TF-IDF z tekstu
- Trenuje model regresji liniowej
- Ocenia wydajnoÅ›Ä‡ i zapisuje model

### 2. ğŸ“Š Pipeline analizy (`main.py`)

```python
# Interaktywny przepÅ‚yw pracy analizy
def interactive_comment_analyzer():
    model, vectorizer = load_model_and_vectorizer()  # Åadowanie pre-trenowanego modelu
    while True:
        comment = input("WprowadÅº komentarz: ")           # Pobieranie danych od uÅ¼ytkownika
        results = get_comment_rating(comment, model, vectorizer)  # Analiza
        display_results(results)                     # WyÅ›wietlanie wynikÃ³w toksycznoÅ›ci
```

**Co siÄ™ dzieje:**
- Åaduje pre-trenowany model natychmiastowo (bez potrzeby trenowania)
- Przetwarza wprowadzenie uÅ¼ytkownika przez wektorizer TF-IDF
- Uzyskuje przewidywania toksycznoÅ›ci dla 7 kategorii
- WyÅ›wietla wyniki z interpretacjami

### 3. ğŸ§ª Pipeline testowania (`test_model.py`)

```python
# Kompleksowy przepÅ‚yw pracy testowania
def test_predefined_comments():
    model, vectorizer = load_model_and_vectorizer()  # Åadowanie modelu
    for test_comment in TEST_COMMENTS:              # Test predefiniowanych przykÅ‚adÃ³w
        results = get_comment_rating(test_comment, model, vectorizer)
        analyze_results(results)                     # PorÃ³wnanie z oczekiwaniami
```

**Co siÄ™ dzieje:**
- Testuje model na predefiniowanych komentarzach o znanym oczekiwanym zachowaniu
- Zapewnia interaktywny tryb testowania dla niestandardowych komentarzy
- WyÅ›wietla szczegÃ³Å‚owe podziaÅ‚y kategorii toksycznoÅ›ci

## ğŸ·ï¸ Kategorie toksycznoÅ›ci

Model analizuje **7 typÃ³w toksycznoÅ›ci**:

| Kategoria | Opis |
|----------|------|
| `toxicity` | OgÃ³lny poziom toksycznoÅ›ci |
| `severe_toxicity` | PowaÅ¼ny poziom toksycznoÅ›ci |
| `obscene` | Wulgarny jÄ™zyk |
| `threat` | GroÅºby i zastraszanie |
| `insult` | Obelgi i ataki osobiste |
| `identity_attack` | Ataki na toÅ¼samoÅ›Ä‡ |
| `sexual_explicit` | TreÅ›ci o charakterze seksualnym |

## ğŸ”§ Dokumentacja moduÅ‚Ã³w

### `config.py` - ZarzÄ…dzanie konfiguracjÄ…
Zawiera wszystkie staÅ‚e, Å›cieÅ¼ki plikÃ³w i parametry modelu:
```python
MODEL_FILE = "models/model.joblib"
LABELS = ["toxicity", "severe_toxicity", ...]
MAX_FEATURES = 5000
```

### `model_utils.py` - ZarzÄ…dzanie modelem
Funkcje do zapisywania, Å‚adowania i sprawdzania modeli:
```python
models_exist() -> bool                    # SprawdÅº czy modele istniejÄ…
save_model_and_vectorizer(model, vec)     # Zapisz wytrenowane modele
load_model_and_vectorizer() -> tuple      # ZaÅ‚aduj zapisane modele
```

### `text_processing.py` - Przetwarzanie tekstu
Wektoryzacja TF-IDF i analiza komentarzy:
```python
create_vectorizer() -> TfidfVectorizer    # UtwÃ³rz procesor TF-IDF
get_comment_rating(comment, model, vec)   # Analizuj pojedynczy komentarz
batch_analyze_comments(comments, ...)     # Analizuj wiele komentarzy
```

## ğŸ“Š Zrozumienie TF-IDF

**TF-IDF (Term Frequency-Inverse Document Frequency)** konwertuje tekst na liczby:

- **TF (Term Frequency)** - jak czÄ™sto sÅ‚owo pojawia siÄ™ w dokumencie
- **IDF (Inverse Document Frequency)** - jak rzadkie jest sÅ‚owo w caÅ‚ym zbiorze
- **Efekt:** WaÅ¼ne sÅ‚owa otrzymujÄ… wyÅ¼sze wartoÅ›ci, czÄ™ste sÅ‚owa niÅ¼sze

**PrzykÅ‚ad:**
- Komentarz: "Ten film jest okropny"
- TF-IDF konwertuje na wektor: [0.0, 0.3, 0.0, 0.8, 0.5, ...]
- KaÅ¼da pozycja odpowiada jednemu sÅ‚owu w sÅ‚owniku

## ğŸ“ˆ Metryki wydajnoÅ›ci modelu

### Mean Squared Error (MSE)
- Mierzy Å›redniÄ… kwadratowÄ… rÃ³Å¼nicÄ™ miÄ™dzy przewidywaniami a rzeczywistymi wartoÅ›ciami
- **NiÅ¼sze jest lepsze** - pokazuje jak daleko sÄ… nasze przewidywania od rzeczywistoÅ›ci

### RÂ² Score (WspÃ³Å‚czynnik determinacji)
- WartoÅ›ci od 0 do 1 (mogÄ… byÄ‡ ujemne dla bardzo zÅ‚ych modeli)
- **BliÅ¼sze 1 jest lepsze** - pokazuje jak dobrze model wyjaÅ›nia dane
- > 0.7 = DoskonaÅ‚y, > 0.5 = Dobry, > 0.3 = Umiarkowany

## ğŸ§ª PrzykÅ‚ady testowe

System automatycznie testuje te scenariusze:

### Test 1: "This is a terrible comment."
- **Oczekiwany rezultat:** Åšrednia toksycznoÅ›Ä‡
- **PowÃ³d:** Zawiera negatywny jÄ™zyk

### Test 2: "This is a very nice comment. Thank you!"
- **Oczekiwany rezultat:** Niska toksycznoÅ›Ä‡
- **PowÃ³d:** Zawiera pozytywne sÅ‚owa

### Test 3: "I want to harm you!"
- **Oczekiwany rezultat:** Wysoka toksycznoÅ›Ä‡
- **PowÃ³d:** Jawna groÅºba

## ğŸ“Š Interpretacja wynikÃ³w

KaÅ¼dy komentarz otrzymuje 7 ocen (po jednej dla kaÅ¼dej etykiety):

```python
# PrzykÅ‚adowy wynik:
[0.1, 0.05, 0.02, 0.8, 0.1, 0.03, 0.01]
#  |     |     |    |    |     |     |
#  |     |     |    |    |     |     â””â”€ sexual_explicit: 0.01 (bardzo niska)
#  |     |     |    |    |     â””â”€ identity_attack: 0.03 (niska) 
#  |     |     |    |    â””â”€ insult: 0.1 (niska)
#  |     |     |    â””â”€ threat: 0.8 (wysoka!) 
#  |     |     â””â”€ obscene: 0.02 (bardzo niska)
#  |     â””â”€ severe_toxicity: 0.05 (niska)
#  â””â”€ toxicity: 0.1 (niska)
```

**Interpretacja:**
- WartoÅ›ci bliskie 0: niska toksycznoÅ›Ä‡
- WartoÅ›ci bliskie 1: wysoka toksycznoÅ›Ä‡  
- W przykÅ‚adzie: komentarz ma wysokÄ… ocenÄ™ za "threat" (groÅºbÄ™)

## ğŸ’¡ PrzykÅ‚ady uÅ¼ycia

### Interaktywna analiza
```bash
$ python main.py
ğŸ’¬ WprowadÅº komentarz do analizy: Hello everyone!

ğŸ“Š WYNIKI ANALIZY TOKSYCZNOÅšCI
Komentarz: 'Hello everyone!'
OgÃ³lna toksycznoÅ›Ä‡: 0.023

SzczegÃ³Å‚owy podziaÅ‚:
        toxicity: 0.023 (BARDZO NISKA)
  severe_toxicity: 0.012 (BARDZO NISKA)
          obscene: 0.008 (BARDZO NISKA)
           threat: 0.015 (BARDZO NISKA)
           insult: 0.019 (BARDZO NISKA)
   identity_attack: 0.011 (BARDZO NISKA)
   sexual_explicit: 0.007 (BARDZO NISKA)

ğŸ¯ INTERPRETACJA: âœ… Bardzo niska toksycznoÅ›Ä‡ - komentarz wydaje siÄ™ bezpieczny
```

### Testowanie wsadowe
```bash
$ python test_model.py
# Wybierz opcjÄ™ 1 dla predefiniowanych testÃ³w
# Wybierz opcjÄ™ 2 dla testowania niestandardowych komentarzy
# Wybierz opcjÄ™ 3 dla trybu interaktywnego
```

## ğŸ“ Koncepty ML - wyjaÅ›nienie

### Co to jest uczenie nadzorowane?
- Mamy dane wejÅ›ciowe (komentarze) i oczekiwane wyniki (oceny toksycznoÅ›ci)
- Model uczy siÄ™ na przykÅ‚adach z prawidÅ‚owymi odpowiedziami
- Potem moÅ¼e przewidywaÄ‡ dla nowych, niewidzianych danych

### Dlaczego dzielimy dane na train/test?
- **Overfitting** - model moÅ¼e "zapamiÄ™taÄ‡" dane treningowe
- Test na oddzielnych danych pokazuje rzeczywistÄ… jakoÅ›Ä‡
- Jak egzamin - nie moÅ¼na siÄ™ uczyÄ‡ z pytaÅ„ egzaminacyjnych

### Regresja vs Klasyfikacja?
- **Klasyfikacja:** przewiduje kategorie (spam/nie spam)
- **Regresja:** przewiduje liczby (poziom toksycznoÅ›ci od 0 do 1)
- UÅ¼ywamy regresji, bo toksycznoÅ›Ä‡ to wartoÅ›Ä‡ ciÄ…gÅ‚a

## ğŸ“– Funkcje zaawansowane

### Niestandardowa analiza komentarzy
```python
from text_processing import get_comment_rating
from model_utils import load_model_and_vectorizer

model, vectorizer = load_model_and_vectorizer()
result = get_comment_rating("TwÃ³j komentarz tutaj", model, vectorizer)
print(f"Wynik toksycznoÅ›ci: {result[0]}")
```

### Przetwarzanie wsadowe
```python
from text_processing import batch_analyze_comments

comments = ["Komentarz 1", "Komentarz 2", "Komentarz 3"]
results = batch_analyze_comments(comments, model, vectorizer)
```

## ğŸ”„ Ulepszenia modelu

### 1. Lepsze przetwarzanie tekstu
```python
# Ulepszona konfiguracja TF-IDF
vectorizer = TfidfVectorizer(
    max_features=10000,      # wiÄ™cej sÅ‚Ã³w
    ngram_range=(1, 2),      # uÅ¼ywaj par sÅ‚Ã³w
    min_df=2,               # ignoruj bardzo rzadkie sÅ‚owa
    stop_words='english'    # usuÅ„ stop words
)
```

### 2. Alternatywne modele
```python
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR

# Random Forest - zwykle lepszy niÅ¼ regresja liniowa
model = RandomForestRegressor(n_estimators=100)

# Support Vector Machine
model = SVR(kernel='rbf')
```

### 3. Walidacja krzyÅ¼owa
```python
from sklearn.model_selection import cross_val_score

# SprawdÅº model na rÃ³Å¼nych podziaÅ‚ach danych
scores = cross_val_score(model, X_train_tfidf, y_train, cv=5)
print(f"Åšredni wynik: {scores.mean():.3f}")
```

## âš ï¸ Ograniczenia

1. **JÄ™zyk:** Model trenowany na jÄ™zyku angielskim
2. **Kontekst:** MoÅ¼e nie rozumieÄ‡ sarkazmu czy ironii
3. **StronniczoÅ›Ä‡:** MoÅ¼e mieÄ‡ uprzedzenia ze zbioru treningowego
4. **Prosty model:** Regresja liniowa ma ograniczenia

## ğŸ› ï¸ RozwiÄ…zywanie problemÃ³w

**Problem:** "Nie znaleziono wytrenowanego modelu"
- **RozwiÄ…zanie:** Uruchom `python train_model.py` najpierw

**Problem:** Program siÄ™ zawiesza lub pokazuje bÅ‚Ä™dy
- **RozwiÄ…zanie:** UsuÅ„ pliki `.joblib` i wytrenuj model ponownie

**Problem:** Dziwne wyniki po aktualizacji kodu
- **RozwiÄ…zanie:** UsuÅ„ stare pliki modelu, aby wytrenowaÄ‡ Å›wieÅ¼y model

**Problem:** NiewystarczajÄ…ca iloÅ›Ä‡ miejsca na dysku
- **RozwiÄ…zanie:** Pliki modelu zajmujÄ… ~50MB - sprawdÅº miejsce na dysku

## ğŸ”„ NastÄ™pne kroki

1. **SprÃ³buj innych modeli:** Random Forest, Neural Networks
2. **Lepsze preprocessing:** stemming, lemmatyzacja
3. **WiÄ™cej danych:** uÅ¼yj wiÄ™kszego zbioru
4. **GÅ‚Ä™bokie uczenie:** BERT, transformers
5. **Lepsza ewaluacja:** wiÄ™cej metryk, confusion matrix

## ğŸ“– Dodatkowe materiaÅ‚y

- [Dokumentacja Scikit-learn](https://scikit-learn.org/)
- [WyjaÅ›nienie TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)
- [ZbiÃ³r danych Civil Comments](https://www.tensorflow.org/datasets/catalog/civil_comments)
- [Dokumentacja angielska](README.md)

---

## ğŸ“„ Open Source

Ten projekt jest open source i dostÄ™pny do celÃ³w edukacyjnych i badawczych. Zapraszam do:

- ğŸ” Studiowania kodu i technik uczenia maszynowego
- ğŸ› ï¸ Modyfikowania i eksperymentowania z rÃ³Å¼nymi modelami
- ğŸ“š Wykorzystania jako zasobu edukacyjnego do projektÃ³w ML
- ğŸ¤ WspÃ³Å‚tworzenia ulepszeÅ„ i poprawek bÅ‚Ä™dÃ³w
- ğŸ“– Dzielenia siÄ™ wiedzÄ… i pomagania innym w nauce

**WspÃ³Å‚tworzenie:**
- Forkuj repozytorium
- TwÃ³rz gaÅ‚Ä™zie funkcji dla swoich zmian
- PrzesyÅ‚aj pull requesty z jasnymi opisami
- Przestrzegaj istniejÄ…cego stylu kodu i standardÃ³w dokumentacji

**UÅ¼ycie edukacyjne:**
Idealne do nauki klasyfikacji tekstu, wektoryzacji TF-IDF, zachowywania modeli i profesjonalnej struktury projektÃ³w Python.

## ğŸ“ Wsparcie

- **Dokumentacja angielska:** [README.md](README.md)
- **Dokumentacja polska:** Ten plik
- **Problemy:** Najpierw sprawdÅº pliki modelu i zaleÅ¼noÅ›ci